{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Rate Estimation using PPG (Random Forests classifier)\n",
    "\n",
    "The data has to be downloaded from [here](https://archive.ics.uci.edu/ml/datasets/PPG-DaLiA), unzipped into the current folder. Different folders for each individual has to be in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the below code to load the data of each individual and process the PPG signal for all the individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:33<00:00,  6.25s/it]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from math import floor\n",
    "from tqdm import tqdm\n",
    "lengths=[]\n",
    "activities = []\n",
    "ppg = []\n",
    "lines = []\n",
    "X = []\n",
    "for i in tqdm(range(1,16)):\n",
    "    st ='S'+str(i)+'/'+'S'+str(i)+'.pkl'\n",
    "    with open(st, 'rb') as f:\n",
    "        temp = pickle.load(f, encoding='latin1')\n",
    "    ppg = temp['signal']['wrist']['BVP'].tolist()\n",
    "    qppg =[]\n",
    "    lengths.append(int(len(ppg)/128)-3)\n",
    "    ac = temp['activity']\n",
    "    tempac =[]\n",
    "    for l in range(int(floor(ac.shape[0]/8))-3):\n",
    "        activities.append(max(ac[l*8:(l+4)*8]))\n",
    "    #print(len(activities),len(temp['label']))\n",
    "    for p in range(int(len(ppg)/128)-3):\n",
    "        t = np.zeros(512)\n",
    "        k = 0\n",
    "        for j in range(p*128,(4+p)*128):\n",
    "            t[k] = ppg[j][0]\n",
    "            k = k+1\n",
    "        qppg.append(t)\n",
    "    X.extend(qppg)\n",
    "    lines.extend(temp['label'])\n",
    "    #activities.extend(temp['activity'].tolist())\n",
    "    #print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = lines\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "y_class = []\n",
    "sort_dict = {}\n",
    "for rate in Y:\n",
    "   fl = floor(rate/5)\n",
    "   ce = ceil(rate/5)\n",
    "   st = str(fl*5) + \"-\" + str(ce*5)\n",
    "   y_class.append(st)\n",
    "   sort_dict[st] = fl-8\n",
    " \n",
    "y_class = np.array(y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['100-105', '105-110', '110-115', '115-120', '120-125', '125-130',\n       '130-135', '135-140', '140-145', '145-150', '150-155', '155-160',\n       '160-165', '165-170', '170-175', '175-180', '180-185', '185-190',\n       '40-45', '45-50', '50-55', '55-60', '60-65', '65-70', '70-75',\n       '75-80', '80-85', '85-90', '90-95', '95-100'], dtype='<U7')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = []\n",
    "for rate in y_class:\n",
    "    temp = np.zeros(30)\n",
    "    temp[sort_dict[rate]] = 1\n",
    "    y_one_hot.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = np.array(y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X and Y has the input and output data for training the model. The total data accounted for 64697 samples and each input sample is of size 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64697, 512) (64697, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output data is spiltted into train and test set using sklearn's train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y_one_hot, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use RandomForestRegressor from sklearn's ensemble learning to train the model. We have used 300 trees to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=300, random_state=0)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using joblib dump the model, so that it can be loaded after and used for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(classifier,\"random_forests_classifer_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = joblib.load('train-classifier-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the accuracy metrics using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5628 0.8698608964451314\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for pred, actual in zip(y_pred,y_test):\n",
    "    if np.argmax(pred)==np.argmax(actual):\n",
    "        counter+=1\n",
    "    \n",
    "print(counter,counter/y_pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52404 0.8999948477510433\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for pred, actual in zip(y_pred,y_train):\n",
    "    if np.argmax(pred)==np.argmax(actual):\n",
    "        counter+=1\n",
    "    \n",
    "print(counter,counter/y_pred.shape[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('3.8')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}